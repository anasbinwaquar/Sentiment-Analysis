{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Python\\Python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w'] not in stop_words.\n  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textstat\n",
    "from nltk.stem import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "\n",
    "def flesch_reading_ease(text):\n",
    "    # formula=206.835-1.015(total_words/1)-84.6(syllables/total_words)\n",
    "    syllables=textstat.syllable_count(text)\n",
    "    words=textstat.lexicon_count(text, removepunct=True)\n",
    "    score=round(206.835-1.015*(words/1)-84.6*(float(syllables/words)),2)\n",
    "    # print(score)\n",
    "    return score\n",
    "\n",
    "def flesch_kincaid_grade_level(text):\n",
    "    # formula=0.39*(total_words/1)+11.8(syllables/total_words)-15.59\n",
    "    syllables=textstat.syllable_count(text)\n",
    "    words=textstat.lexicon_count(text, removepunct=True)\n",
    "    score=round(0.39*(words/1)+11.8*(syllables/words)-15.59,2)\n",
    "    # print(score)\n",
    "    return score\n",
    "\n",
    "def total_characters(text):\n",
    "    count=0\n",
    "    for char in text:\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "#Remove extra white spaces, urls , mentions\n",
    "def preprocess(text):\n",
    "    text=text.lower()   \n",
    "    # print(stopwords)\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "    '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def tokenization_with_stemming(text):\n",
    "    stemmer=PorterStemmer()\n",
    "    # \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
    "    # and stems tweets. Returns a list of stemmed tokens.\"\"\"\n",
    "    # text = \" \".join(re.split(\"[^a-zA-Z]*\", text.lower())).strip()\n",
    "    tokens = [stemmer.stem(t) for t in text.split()]\n",
    "    # print(tokens)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def tokenize(text):\n",
    "    text = \" \".join(re.split(\"[^a-zA-Z.,!?]*\", text.lower())).strip()\n",
    "    return text.split()\n",
    "\n",
    "def set_class(text):\n",
    "    if text=='NAG':\n",
    "        return 2\n",
    "    elif text=='OAG':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def preprocessing():\n",
    "    path = pathlib.Path(__file__).parent.absolute()\n",
    "    path = str(path)\n",
    "    #Loading file set to data frame\n",
    "    df=pd.read_csv(path + \"\\\\trac-gold-set\\\\agr_en_fb_gold.csv\", encoding = \"utf-8\")\n",
    "    #Case folding and porter stemming\n",
    "    # df[\"preprocess\"]=df[\"text\"].apply(lambda x:x.lower())\n",
    "    df[\"preprocess\"]=df[\"text\"].apply(lambda x:preprocess(x))\n",
    "    # print(df['preprocess'])\n",
    "    df[\"flesch_reading_ease\"]=df[\"text\"].apply(lambda x:flesch_reading_ease(x))\n",
    "    df[\"flesch_kincaid_grade_level\"]=df[\"text\"].apply(lambda x:flesch_kincaid_grade_level(x))\n",
    "    df[\"syllables\"]=df[\"text\"].apply(lambda x:textstat.syllable_count(x))\n",
    "    df[\"words\"]=df[\"text\"].apply(lambda x:textstat.lexicon_count(x))\n",
    "    df[\"characters\"]=df[\"text\"].apply(lambda x:total_characters(x))\n",
    "    df[\"class\"]=df[\"aggresssion-level\"].apply(lambda x:set_class(x))\n",
    "    #Export processed CSV\n",
    "    # print(df.text)\n",
    "    df.to_csv('processed_data.csv')\n",
    "    # df.describe()\n",
    "\n",
    "def features(text):\n",
    "    sentiment_analyzer=VS()\n",
    "    sentiment = sentiment_analyzer.polarity_scores(text)\n",
    "    \n",
    "    words = preprocess(text) #Get text only\n",
    "    syllables = textstat.syllable_count(words)\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(text)\n",
    "    num_terms = len(text.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "    \n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = flesch_kincaid_grade_level(text)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = flesch_reading_ease(text)\n",
    "    features = [FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound']]\n",
    "    #features = pandas.DataFrame(features)\n",
    "    return features\n",
    "\n",
    "def get_feature_array(text):\n",
    "    feats=[]\n",
    "    for t in text:\n",
    "        feats.append(features(t))\n",
    "    return np.array(feats)\n",
    "\n",
    "other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syllables_per_sent\", \"num_chars\", \"num_chars_total\",\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\",\"vader pos\",\"vader neu\", \n",
    "                        \"vader compound\"]\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "# preprocessing()\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=tokenize,\n",
    "    preprocessor=preprocess,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=stopwords,\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=10000,\n",
    "    min_df=5,\n",
    "    max_df=0.75\n",
    "    )\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "df=pd.read_csv(\"labeled_data.csv\")\n",
    "text=df.tweet\n",
    "tfidf = vectorizer.fit_transform(text).toarray()\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()} #keys are indices; values are IDF scores\n",
    "# print(idf_dict) \n",
    "# other_features=list()\n",
    "features=get_feature_array(text)\n",
    "# print(features)\n",
    "\n",
    "#Get parts of speech tags for text and save as a string\n",
    "text_tag = []\n",
    "for t in text:\n",
    "    tokens = tokenize(preprocess(t))\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tag_list = [x[1] for x in tags]\n",
    "    tag_str = \" \".join(tag_list)\n",
    "    text_tag.append(tag_str)\n",
    "\n",
    "pos_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=None,\n",
    "    lowercase=False,\n",
    "    preprocessor=None,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=None,\n",
    "    use_idf=False,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=5000,\n",
    "    min_df=5,\n",
    "    max_df=0.75,\n",
    "    )\n",
    "pos = pos_vectorizer.fit_transform(pd.Series(text_tag)).toarray()\n",
    "pos_vocab = {v:i for i, v in enumerate(pos_vectorizer.get_feature_names())}\n",
    "\n",
    "M = np.concatenate([tfidf,pos,features],axis=1)\n",
    "# print(M.shape)\n",
    "#Finally get a list of variable names\n",
    "variables = ['']*len(vocab)\n",
    "for k,v in vocab.items():\n",
    "    variables[v] = k\n",
    "\n",
    "pos_variables = ['']*len(pos_vocab)\n",
    "for k,v in pos_vocab.items():\n",
    "    pos_variables[v] = k\n",
    "\n",
    "feature_names = variables+pos_variables+other_features_names\n",
    "X = pd.DataFrame(M)\n",
    "print (M)\n",
    "y = df['class'].astype(int)\n",
    "param_grid = [{}] # Optionally add parameters here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "        [('select', SelectFromModel(LogisticRegression(solver='newton-cg',class_weight='balanced',\n",
    "                                                  penalty=\"l2\", C=0.01))),\n",
    "        ('model', LogisticRegression(solver='newton-cg',class_weight='balanced',penalty='l2'))])\n",
    "param_grid = [{}] # Optionally add parameters here\n",
    "grid_search = GridSearchCV(pipe, \n",
    "                           param_grid,\n",
    "                           cv=StratifiedKFold(n_splits=5).split(X_train, y_train), \n",
    "                           verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] END .................................................... total time= 4.1min\n",
      "[CV] END .................................................... total time= 4.4min\n",
      "[CV] END .................................................... total time= 4.2min\n",
      "[CV] END .................................................... total time= 4.3min\n",
      "[CV] END .................................................... total time= 5.1min\n"
     ]
    }
   ],
   "source": [
    "model = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report( y_test, y_preds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.23      0.39      0.29       157\n           1       0.90      0.83      0.86      1891\n           2       0.64      0.71      0.67       431\n\n    accuracy                           0.78      2479\n   macro avg       0.59      0.64      0.61      2479\nweighted avg       0.81      0.78      0.79      2479\n\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,y_preds)\n",
    "matrix_proportions = np.zeros((3,3))\n",
    "for i in range(0,3):\n",
    "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
    "names=['Hate','Offensive','Neither']\n",
    "confusion_df = pd.DataFrame(matrix_proportions, index=names,columns=names)\n",
    "plt.figure(figsize=(5,5))\n",
    "seaborn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='gist_gray_r',cbar=False, square=True,fmt='.2f')\n",
    "plt.ylabel(r'True categories',fontsize=14)\n",
    "plt.xlabel(r'Predicted categories',fontsize=14)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "#Uncomment line below if you want to save the output\n",
    "#plt.savefig('confusion.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}